{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze word and phones counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words_phones(alignments, words_counts, phones_counts):\n",
    "    \"\"\"\n",
    "    Count the number of words and phones\n",
    "    \"\"\"\n",
    "    for key in alignments:\n",
    "        for xmin, xmax, text in alignments[key]:\n",
    "            if key == 'phones':\n",
    "                if text not in phones_counts:\n",
    "                   phones_counts[text] = 0\n",
    "                phones_counts[text] += 1\n",
    "            if key == 'words':\n",
    "                if text not in words_counts:\n",
    "                   words_counts[text] = 0\n",
    "                words_counts[text] += 1\n",
    "    return words_counts, phones_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from utils_alignments import parse_textgrid\n",
    "\n",
    "alignments_dir = '../datasets/alignments'\n",
    "\n",
    "words_counts = {}\n",
    "phones_counts = {}\n",
    "\n",
    "for root, dirs, files in os.walk(alignments_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\".TextGrid\"):\n",
    "            textgrid_path = os.path.join(root, file)\n",
    "            alignments = parse_textgrid(textgrid_path)\n",
    "            words_counts, phones_counts  = count_words_phones(alignments, words_counts, phones_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "file_name = 'words_counts.json'\n",
    "\n",
    "with open(file_name, 'w') as file:\n",
    "    json.dump(words_counts, file, indent=4)\n",
    "\n",
    "file_name1 = 'phones_counts.json'\n",
    "\n",
    "with open(file_name1, 'w') as file:\n",
    "    json.dump(phones_counts, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sil': 5082,\n",
       " 'AY1': 6080,\n",
       " 'W': 8340,\n",
       " 'UH1': 1774,\n",
       " 'D': 17977,\n",
       " 'AH0': 29414,\n",
       " 'N': 26333,\n",
       " 'T': 25466,\n",
       " 'G': 3260,\n",
       " 'IH1': 9551,\n",
       " 'V': 7719,\n",
       " 'HH': 8071,\n",
       " 'AE1': 9801,\n",
       " 'F': 6836,\n",
       " 'P': 6936,\n",
       " 'EH2': 498,\n",
       " 'IY0': 7108,\n",
       " 'R': 15513,\n",
       " 'ER0': 8352,\n",
       " 'DH': 11685,\n",
       " 'AH1': 8134,\n",
       " 'OW1': 4051,\n",
       " 'L': 14913,\n",
       " 'AA1': 4739,\n",
       " 'sp': 16887,\n",
       " 'M': 10784,\n",
       " 'AY2': 351,\n",
       " 'K': 9849,\n",
       " 'EH1': 10214,\n",
       " 'IH0': 13416,\n",
       " 'S': 17463,\n",
       " 'IY1': 6738,\n",
       " 'EY1': 5407,\n",
       " 'Z': 10575,\n",
       " 'UW1': 4305,\n",
       " 'AA2': 207,\n",
       " 'B': 6440,\n",
       " 'OY1': 366,\n",
       " 'SH': 2912,\n",
       " 'ER1': 2142,\n",
       " 'AO1': 4942,\n",
       " 'CH': 2158,\n",
       " 'TH': 2417,\n",
       " 'NG': 3880,\n",
       " 'JH': 1672,\n",
       " 'Y': 2554,\n",
       " 'UW0': 382,\n",
       " 'AW1': 2131,\n",
       " 'AH2': 172,\n",
       " 'OW2': 198,\n",
       " 'IH2': 403,\n",
       " 'spn': 356,\n",
       " 'OW0': 510,\n",
       " 'EH0': 253,\n",
       " 'EY2': 320,\n",
       " 'AE0': 116,\n",
       " 'ZH': 186,\n",
       " 'UW2': 134,\n",
       " 'AY0': 109,\n",
       " 'AE2': 265,\n",
       " 'AO2': 168,\n",
       " 'AA0': 131,\n",
       " 'UH2': 40,\n",
       " 'EY0': 46,\n",
       " 'AW2': 79,\n",
       " 'AO0': 87,\n",
       " 'IY2': 173,\n",
       " 'ER2': 32,\n",
       " 'OY2': 8,\n",
       " 'UH0': 12,\n",
       " 'AW0': 9}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phones_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_dict = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], \"float32\")\n",
    "            embeddings_dict[word] = vector\n",
    "    return embeddings_dict\n",
    "\n",
    "\n",
    "def get_embeddings_glove(input_text, glove_embeddings):\n",
    "    words = input_text.split()\n",
    "    \n",
    "    embeddings = {\n",
    "        word: [glove_embeddings.get(word, None)] * 12 for word in words\n",
    "    }\n",
    "    \n",
    "    # Filter out words that are not found in the GloVe embeddings\n",
    "    embeddings = {\n",
    "        word: vecs for word, vecs in embeddings.items() if vecs[0] is not None\n",
    "    }\n",
    "    \n",
    "    return embeddings    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_file_path = '../datasets/glove.42B.300d.txt'\n",
    "\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path)\n",
    "input_text = 'hi how are you'\n",
    "embeddings_audio = get_embeddings_glove(input_text, glove_embeddings)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = glove_embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11715"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words_counts.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'affrightened',\n",
       " \"ain't\",\n",
       " \"alexander's\",\n",
       " \"ann's\",\n",
       " \"anne's\",\n",
       " \"another's\",\n",
       " \"antonia's\",\n",
       " \"apostle's\",\n",
       " \"aren't\",\n",
       " \"argyle's\",\n",
       " \"aunt's\",\n",
       " \"author's\",\n",
       " \"baby's\",\n",
       " \"balaam's\",\n",
       " \"bear's\",\n",
       " \"beggar's\",\n",
       " 'blacknesses',\n",
       " \"blanco's\",\n",
       " 'blemmyes',\n",
       " \"boy's\",\n",
       " \"brewer's\",\n",
       " \"bright's\",\n",
       " \"brother's\",\n",
       " \"brown's\",\n",
       " \"bubble's\",\n",
       " 'bunnit',\n",
       " \"captain's\",\n",
       " \"captive's\",\n",
       " \"carpaccio's\",\n",
       " \"catherine's\",\n",
       " \"charlie's\",\n",
       " \"chaucer's\",\n",
       " \"child's\",\n",
       " \"children's\",\n",
       " \"christ's\",\n",
       " \"chunky's\",\n",
       " \"church's\",\n",
       " \"clergyman's\",\n",
       " \"commandant's\",\n",
       " \"connell's\",\n",
       " \"consid'ble\",\n",
       " 'constrainedly',\n",
       " \"consumer's\",\n",
       " \"cook's\",\n",
       " \"couldn't\",\n",
       " \"country's\",\n",
       " \"court's\",\n",
       " \"cousin's\",\n",
       " 'creeters',\n",
       " \"culprit's\",\n",
       " \"cumberland's\",\n",
       " \"customer's\",\n",
       " \"cynthia's\",\n",
       " \"dante's\",\n",
       " \"daren't\",\n",
       " \"darwin's\",\n",
       " \"david's\",\n",
       " \"dawn's\",\n",
       " \"day's\",\n",
       " \"delia's\",\n",
       " \"dent's\",\n",
       " \"detective's\",\n",
       " \"dinah's\",\n",
       " 'disburdened',\n",
       " 'dorriforth',\n",
       " \"dragon's\",\n",
       " \"dramatist's\",\n",
       " \"druggist's\",\n",
       " \"dummy's\",\n",
       " 'egoisms',\n",
       " \"either's\",\n",
       " \"elmo's\",\n",
       " \"else's\",\n",
       " \"emperor's\",\n",
       " \"enemy's\",\n",
       " 'enthralment',\n",
       " 'epicurism',\n",
       " \"eva's\",\n",
       " \"ever'body\",\n",
       " \"excellency's\",\n",
       " \"factor's\",\n",
       " \"farmer's\",\n",
       " \"father's\",\n",
       " \"feelin's\",\n",
       " \"fellow's\",\n",
       " 'flamelets',\n",
       " \"floyd's\",\n",
       " \"forbes's\",\n",
       " \"foster's\",\n",
       " \"francisco's\",\n",
       " \"frederick's\",\n",
       " \"friend's\",\n",
       " \"fugitive's\",\n",
       " \"gardener's\",\n",
       " \"gentleman's\",\n",
       " \"geoffrey's\",\n",
       " \"gilchrist's\",\n",
       " 'gillikins',\n",
       " \"girl's\",\n",
       " \"gladden's\",\n",
       " \"goat's\",\n",
       " \"god's\",\n",
       " 'gossoons',\n",
       " \"governor's\",\n",
       " \"grey's\",\n",
       " \"griffin's\",\n",
       " \"groom's\",\n",
       " 'guidest',\n",
       " \"guy's\",\n",
       " \"hadn't\",\n",
       " \"hamilton's\",\n",
       " \"hamlet's\",\n",
       " \"hand's\",\n",
       " \"harry's\",\n",
       " \"hasn't\",\n",
       " \"haven't\",\n",
       " \"hawk's\",\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " \"heart's\",\n",
       " \"heaven's\",\n",
       " \"henry's\",\n",
       " 'hepsey',\n",
       " \"hepzibah's\",\n",
       " \"her's\",\n",
       " \"here's\",\n",
       " \"hilda's\",\n",
       " \"hobson's\",\n",
       " 'hochheimer',\n",
       " \"hopkins's\",\n",
       " \"hour's\",\n",
       " \"household's\",\n",
       " \"hugh's\",\n",
       " \"husband's\",\n",
       " 'inexhausted',\n",
       " \"iron's\",\n",
       " \"isn't\",\n",
       " \"it'll\",\n",
       " \"jack's\",\n",
       " \"jacob's\",\n",
       " \"jane's\",\n",
       " \"jasper's\",\n",
       " \"jem's\",\n",
       " \"jeweler's\",\n",
       " \"jim's\",\n",
       " \"journey's\",\n",
       " \"julian's\",\n",
       " \"kate's\",\n",
       " \"king's\",\n",
       " \"kitty's\",\n",
       " \"lady's\",\n",
       " \"lake's\",\n",
       " 'languishingly',\n",
       " \"lassen's\",\n",
       " \"latter's\",\n",
       " \"laugh'd\",\n",
       " \"leighton's\",\n",
       " \"let's\",\n",
       " \"letty's\",\n",
       " \"linnell's\",\n",
       " \"look'd\",\n",
       " \"lou's\",\n",
       " \"lucy's\",\n",
       " \"luther's\",\n",
       " \"madame's\",\n",
       " \"maid's\",\n",
       " \"majesty's\",\n",
       " 'malignities',\n",
       " \"man's\",\n",
       " \"marie's\",\n",
       " \"mary's\",\n",
       " \"mason's\",\n",
       " \"master's\",\n",
       " \"men's\",\n",
       " \"merchant's\",\n",
       " 'mingoes',\n",
       " \"minister's\",\n",
       " 'minnetaki',\n",
       " \"minnie's\",\n",
       " \"moment's\",\n",
       " \"montrose's\",\n",
       " \"more's\",\n",
       " \"mother's\",\n",
       " \"mule's\",\n",
       " \"nature's\",\n",
       " \"need'st\",\n",
       " \"newsome's\",\n",
       " \"nightingale's\",\n",
       " \"nobleman's\",\n",
       " \"nobody's\",\n",
       " \"norman's\",\n",
       " \"north's\",\n",
       " \"novel's\",\n",
       " \"one's\",\n",
       " \"opinion's\",\n",
       " \"opponent's\",\n",
       " \"other's\",\n",
       " \"ottley's\",\n",
       " \"oughtn't\",\n",
       " 'overmasters',\n",
       " \"papa's\",\n",
       " \"paul's\",\n",
       " \"pearl's\",\n",
       " \"people's\",\n",
       " \"peter's\",\n",
       " 'petronels',\n",
       " \"philly's\",\n",
       " \"philosopher's\",\n",
       " \"pierc'd\",\n",
       " 'pigstye',\n",
       " \"plato's\",\n",
       " 'plebeianism',\n",
       " \"poison'd\",\n",
       " \"polly's\",\n",
       " \"possess'd\",\n",
       " 'pravity',\n",
       " 'precieuses',\n",
       " \"professor's\",\n",
       " 'quakerish',\n",
       " \"queen's\",\n",
       " \"rachel's\",\n",
       " 'raimented',\n",
       " \"rainbow's\",\n",
       " \"randal's\",\n",
       " \"rector's\",\n",
       " \"redman's\",\n",
       " \"regent's\",\n",
       " \"remov'd\",\n",
       " \"resign'd\",\n",
       " \"robin's\",\n",
       " \"rogers's\",\n",
       " \"sailor's\",\n",
       " \"sarah's\",\n",
       " \"saturday's\",\n",
       " \"second's\",\n",
       " \"shakespeare's\",\n",
       " \"shan't\",\n",
       " \"she'd\",\n",
       " \"sheep's\",\n",
       " \"shelley's\",\n",
       " \"sheriff's\",\n",
       " \"ship's\",\n",
       " \"shouldn't\",\n",
       " \"singer's\",\n",
       " 'sippet',\n",
       " 'sippets',\n",
       " \"sister's\",\n",
       " \"solon's\",\n",
       " \"somebody's\",\n",
       " \"southey's\",\n",
       " 'spilth',\n",
       " \"squire's\",\n",
       " \"state's\",\n",
       " \"steel'd\",\n",
       " \"stephen's\",\n",
       " \"stepp'd\",\n",
       " \"stevie's\",\n",
       " 'stommick',\n",
       " \"stone's\",\n",
       " \"story's\",\n",
       " \"stroller's\",\n",
       " \"summer's\",\n",
       " \"sun's\",\n",
       " \"swift's\",\n",
       " \"sydney's\",\n",
       " \"tabby's\",\n",
       " \"tad's\",\n",
       " \"that'll\",\n",
       " \"there'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " \"thrall's\",\n",
       " \"time's\",\n",
       " 'tintoret',\n",
       " \"tom's\",\n",
       " 'tonnay',\n",
       " \"tony's\",\n",
       " \"trevelyan's\",\n",
       " \"trot's\",\n",
       " \"trout's\",\n",
       " \"turner's\",\n",
       " \"twasn't\",\n",
       " 'unbarring',\n",
       " 'uncloud',\n",
       " 'unexceptionably',\n",
       " 'unsoldierly',\n",
       " 'untruss',\n",
       " 'veolan',\n",
       " \"verne's\",\n",
       " \"voltaire's\",\n",
       " \"wabi's\",\n",
       " \"wabigoon's\",\n",
       " \"wasn't\",\n",
       " \"waverley's\",\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " \"weren't\",\n",
       " \"who's\",\n",
       " \"wife's\",\n",
       " 'wildering',\n",
       " \"witch's\",\n",
       " \"wizard's\",\n",
       " \"woman's\",\n",
       " \"women's\",\n",
       " \"won't\",\n",
       " 'woonga',\n",
       " 'woongas',\n",
       " \"world's\",\n",
       " \"wouldn't\",\n",
       " \"wrangler's\",\n",
       " \"year's\",\n",
       " \"you'd\",\n",
       " \"zora's\"}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(words_counts.keys()) - set(glove_embeddings.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words_counts.keys()) - set(glove_embeddings.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
