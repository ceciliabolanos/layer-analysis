{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID SEX           SUBSET  MINUTES              NAME\n",
      "0       14   F  train-clean-360    25.03   Kristin LeMoine\n",
      "1       16   F  train-clean-360    25.11    Alys AtteWater\n",
      "2       17   M  train-clean-360    25.04    Gord Mackenzie\n",
      "3       19   F  train-clean-100    25.19  Kara Shallenberg\n",
      "4       20   F  train-other-500    30.07            Gesine\n",
      "...    ...  ..              ...      ...               ...\n",
      "2479  8975   F  train-clean-100    25.11       Daisy Flaim\n",
      "2480  9000   M  train-other-500    27.26   Ramon Escamilla\n",
      "2481  9022   F  train-clean-360    25.17          Claire M\n",
      "2482  9023   F  train-clean-360    25.19      P. J. Morgan\n",
      "2483  9026   F  train-clean-360    21.75      Tammy Porter\n",
      "\n",
      "[2484 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '/home/cbolanos/datasets/librispeech-raw/SPEAKERS.TXT'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "content_io = io.StringIO(content)\n",
    "\n",
    "# Skip the comments and header\n",
    "lines = [line.strip() for line in content_io if not line.startswith(';') and line.strip()]\n",
    "\n",
    "# Process each line manually\n",
    "data = []\n",
    "for line in lines:\n",
    "    parts = line.split('|')\n",
    "    if len(parts) >= 5:  # Ensure we have at least 5 parts\n",
    "        id_, sex, subset, minutes, name = parts[0], parts[1], parts[2], parts[3], '|'.join(parts[4:])\n",
    "        data.append([id_.strip(), sex.strip(), subset.strip(), minutes.strip(), name.strip()])\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data, columns=['ID', 'SEX', 'SUBSET', 'MINUTES', 'NAME'])\n",
    "\n",
    "# Clean up the data\n",
    "df['ID'] = df['ID'].astype(int)\n",
    "df['MINUTES'] = df['MINUTES'].astype(float)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_devclean = df[df['SUBSET'] == 'dev-clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3374639/3284644449.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_devclean['ID'] = df_devclean['ID'].astype(str)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SEX</th>\n",
       "      <th>SUBSET</th>\n",
       "      <th>MINUTES</th>\n",
       "      <th>NAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>84</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.02</td>\n",
       "      <td>Christie Nowak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>174</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.04</td>\n",
       "      <td>Peter Eastman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>251</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.04</td>\n",
       "      <td>Mark Nelson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>422</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.38</td>\n",
       "      <td>President Lethe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>652</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.31</td>\n",
       "      <td>Scott Walter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>777</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.06</td>\n",
       "      <td>fling93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>1272</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.02</td>\n",
       "      <td>John Rose</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>529</th>\n",
       "      <td>1462</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.04</td>\n",
       "      <td>E. Tavano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>1673</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.07</td>\n",
       "      <td>Tonia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>681</th>\n",
       "      <td>1919</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.17</td>\n",
       "      <td>nprigoda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1988</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.16</td>\n",
       "      <td>Ransom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>1993</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.11</td>\n",
       "      <td>Wendy Belcher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717</th>\n",
       "      <td>2035</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.11</td>\n",
       "      <td>Sharon Bautista</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2078</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Kathy Caver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>2086</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.04</td>\n",
       "      <td>Nicodemus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>2277</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.01</td>\n",
       "      <td>zinniz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>2412</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.06</td>\n",
       "      <td>calystra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>2428</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.02</td>\n",
       "      <td>Stephen Kinford</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>2803</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.20</td>\n",
       "      <td>aquielisunari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>2902</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>dexter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>3000</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.03</td>\n",
       "      <td>Brian von Dedenroth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>3081</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.00</td>\n",
       "      <td>Renata</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>3170</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>VOICEGUY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1086</th>\n",
       "      <td>3536</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.15</td>\n",
       "      <td>Arielle Lipshaw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>3576</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.00</td>\n",
       "      <td>JudyGibson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>3752</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.06</td>\n",
       "      <td>Mark Welch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1167</th>\n",
       "      <td>3853</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.05</td>\n",
       "      <td>M. Bertke</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>5338</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.07</td>\n",
       "      <td>S R Colon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>5536</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.13</td>\n",
       "      <td>David Mix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>5694</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.01</td>\n",
       "      <td>Winston Tharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>5895</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.02</td>\n",
       "      <td>iamartin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>6241</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.05</td>\n",
       "      <td>badey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>6295</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.04</td>\n",
       "      <td>Michael Packard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>6313</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.17</td>\n",
       "      <td>Jennifer Wiginton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>6319</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.01</td>\n",
       "      <td>thestorygirl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>6345</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.07</td>\n",
       "      <td>Jean Bascom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>7850</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.06</td>\n",
       "      <td>Jill Engle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2256</th>\n",
       "      <td>7976</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.13</td>\n",
       "      <td>JenniferRutters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>8297</td>\n",
       "      <td>M</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.04</td>\n",
       "      <td>David Mecionis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2470</th>\n",
       "      <td>8842</td>\n",
       "      <td>F</td>\n",
       "      <td>dev-clean</td>\n",
       "      <td>8.10</td>\n",
       "      <td>Mary J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID SEX     SUBSET  MINUTES                 NAME\n",
       "46      84   F  dev-clean     8.02       Christie Nowak\n",
       "93     174   M  dev-clean     8.04        Peter Eastman\n",
       "135    251   M  dev-clean     8.04          Mark Nelson\n",
       "200    422   M  dev-clean     8.38      President Lethe\n",
       "279    652   M  dev-clean     8.31         Scott Walter\n",
       "318    777   M  dev-clean     8.06              fling93\n",
       "470   1272   M  dev-clean     8.02            John Rose\n",
       "529   1462   F  dev-clean     8.04            E. Tavano\n",
       "595   1673   F  dev-clean     8.07                Tonia\n",
       "681   1919   F  dev-clean     8.17             nprigoda\n",
       "700   1988   F  dev-clean     8.16               Ransom\n",
       "703   1993   F  dev-clean     8.11        Wendy Belcher\n",
       "717   2035   F  dev-clean     8.11      Sharon Bautista\n",
       "733   2078   M  dev-clean     8.03          Kathy Caver\n",
       "735   2086   M  dev-clean     8.04            Nicodemus\n",
       "786   2277   F  dev-clean     8.01               zinniz\n",
       "823   2412   F  dev-clean     8.06             calystra\n",
       "827   2428   M  dev-clean     8.02      Stephen Kinford\n",
       "911   2803   M  dev-clean     8.20        aquielisunari\n",
       "928   2902   M  dev-clean     8.10               dexter\n",
       "954   3000   M  dev-clean     8.03  Brian von Dedenroth\n",
       "976   3081   F  dev-clean     8.00               Renata\n",
       "1003  3170   M  dev-clean     8.10             VOICEGUY\n",
       "1086  3536   F  dev-clean     8.15      Arielle Lipshaw\n",
       "1104  3576   F  dev-clean     8.00           JudyGibson\n",
       "1144  3752   M  dev-clean     8.06           Mark Welch\n",
       "1167  3853   F  dev-clean     8.05            M. Bertke\n",
       "1542  5338   F  dev-clean     8.07            S R Colon\n",
       "1578  5536   M  dev-clean     8.13            David Mix\n",
       "1615  5694   M  dev-clean     8.01        Winston Tharp\n",
       "1665  5895   F  dev-clean     8.02             iamartin\n",
       "1766  6241   M  dev-clean     8.05                badey\n",
       "1782  6295   M  dev-clean     8.04      Michael Packard\n",
       "1786  6313   F  dev-clean     8.17    Jennifer Wiginton\n",
       "1788  6319   F  dev-clean     8.01         thestorygirl\n",
       "1796  6345   F  dev-clean     8.07          Jean Bascom\n",
       "2223  7850   F  dev-clean     8.06           Jill Engle\n",
       "2256  7976   M  dev-clean     8.13      JenniferRutters\n",
       "2348  8297   M  dev-clean     8.04       David Mecionis\n",
       "2470  8842   F  dev-clean     8.10               Mary J"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_devclean['ID'] = df_devclean['ID'].astype(str)\n",
    "df_devclean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Cantidad de Palabras Dichas\n",
      "0    777                         1492\n",
      "1   1988                         1456\n",
      "2   2086                         1413\n",
      "3   3000                         1233\n",
      "4   2902                         1308\n",
      "5   1462                         1366\n",
      "6   3170                         1384\n",
      "7   5536                         1501\n",
      "8   7850                         1259\n",
      "9   1272                         1150\n",
      "10  3576                         1301\n",
      "11  6313                         1598\n",
      "12  2412                         1568\n",
      "13  8297                         1150\n",
      "14  6295                         1262\n",
      "15  2078                         1140\n",
      "16  1993                         1412\n",
      "17  7976                         1449\n",
      "18  2035                         1378\n",
      "19  1673                         1392\n",
      "20  6241                         1517\n",
      "21   422                         1286\n",
      "22   174                         1160\n",
      "23  3536                         1531\n",
      "24  2277                         1592\n",
      "25  5895                         1204\n",
      "26  3752                         1312\n",
      "27  2428                         1382\n",
      "28  5694                         1462\n",
      "29  6345                         1625\n",
      "30  8842                         1493\n",
      "31   652                         1393\n",
      "32  6319                         1245\n",
      "33  1919                         1280\n",
      "34  3081                         1159\n",
      "35  5338                         1348\n",
      "36   251                         1196\n",
      "37  3853                         1499\n",
      "38  2803                         1137\n",
      "39    84                         1369\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('alignments/audio_alignments_10_16.json', 'r') as file:\n",
    "    data = json.load(file)  \n",
    "\n",
    "def process_transcripts(data):\n",
    "    result = {}\n",
    "    for key, value in data.items():\n",
    "        # Extract the ID from the key (assuming it's always the first number in the path)\n",
    "        id = key.split('/')[4]\n",
    "        \n",
    "        # Count words in the transcript\n",
    "        word_count = len(value['transcript_audio'].split())\n",
    "        if id in result:\n",
    "            result[id] += word_count\n",
    "        else:\n",
    "            # If it's a new key, create a new list\n",
    "            result[id] = word_count\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Process the data\n",
    "result = process_transcripts(data)\n",
    "\n",
    "df_words = pd.DataFrame(list(result.items()), columns=['ID', 'Cantidad de Palabras Dichas'])\n",
    "df_words['ID'] = df_words['ID'].astype(str)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ID  Cantidad de Palabras Obtenidas\n",
      "0   1272                            1035\n",
      "1   1462                            1186\n",
      "2   1673                            1083\n",
      "3    174                             960\n",
      "4   1919                            1095\n",
      "5   1988                            1270\n",
      "6   1993                            1213\n",
      "7   2035                            1204\n",
      "8   2078                             929\n",
      "9   2086                            1245\n",
      "10  2277                            1435\n",
      "11  2412                            1346\n",
      "12  2428                            1218\n",
      "13   251                            1065\n",
      "14  2803                            1001\n",
      "15  2902                            1050\n",
      "16  3000                            1031\n",
      "17  3081                            1070\n",
      "18  3170                            1149\n",
      "19  3536                            1318\n",
      "20  3576                            1084\n",
      "21  3752                            1146\n",
      "22  3853                            1281\n",
      "23   422                            1000\n",
      "24  5338                            1166\n",
      "25  5536                            1262\n",
      "26  5694                            1248\n",
      "27  5895                            1076\n",
      "28  6241                            1329\n",
      "29  6295                            1120\n",
      "30  6313                            1412\n",
      "31  6319                            1095\n",
      "32  6345                            1376\n",
      "33   652                            1188\n",
      "34   777                            1309\n",
      "35  7850                            1127\n",
      "36  7976                            1285\n",
      "37  8297                            1026\n",
      "38    84                            1216\n",
      "39  8842                            1257\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('words_in_order1.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Create a new dictionary\n",
    "new_dict = {}\n",
    "\n",
    "# Process each key-value pair in the original dictionary\n",
    "for key, value in data.items():\n",
    "    # Extract the first element of the key (before the first hyphen)\n",
    "    new_key = key.split('-')[0]\n",
    "    \n",
    "    # If the key already exists in the new dictionary, extend the list\n",
    "    if new_key in new_dict:\n",
    "        new_dict[new_key].extend(value)\n",
    "    else:\n",
    "        # If it's a new key, create a new list\n",
    "        new_dict[new_key] = value\n",
    "\n",
    "count_dict = {}\n",
    "\n",
    "# Count the length of each value in the new dictionary\n",
    "for key, value in new_dict.items():\n",
    "    count_dict[key] = len(value)\n",
    "\n",
    "# Print the count dictionary\n",
    "df_words_obtenidas = pd.DataFrame(list(count_dict.items()), columns=['ID', 'Cantidad de Palabras Obtenidas'])\n",
    "df_words_obtenidas['ID'] = df_words_obtenidas['ID'].astype(str)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df_words_obtenidas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(df_devclean, df_words, on='ID', how='inner')\n",
    "merged_df_final = pd.merge(merged_df, df_words_obtenidas, on='ID', how='inner')\n",
    "merged_df_final = merged_df_final[['ID', 'SEX', 'Cantidad de Palabras Dichas', 'Cantidad de Palabras Obtenidas']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de palabras obtenidas en total: 46906\n",
      "Cantidad de palabras obtenidas por mujeres: 24310\n",
      "Cantidad de palabras obtenidas por hombres: 22596\n",
      "Cantidad de palabras dichas en total: 54402\n",
      "Cantidad de palabras dichas por mujeres: 28075\n",
      "Cantidad de palabras dichas por hombres: 26327\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de palabras obtenidas en total: {merged_df_final['Cantidad de Palabras Obtenidas'].sum()}\") \n",
    "print(f\"Cantidad de palabras obtenidas por mujeres: {merged_df_final[merged_df_final['SEX'] == 'F']['Cantidad de Palabras Obtenidas'].sum()}\") \n",
    "print(f\"Cantidad de palabras obtenidas por hombres: {merged_df_final[merged_df_final['SEX'] == 'M']['Cantidad de Palabras Obtenidas'].sum()}\") \n",
    "print(f\"Cantidad de palabras dichas en total: {merged_df_final['Cantidad de Palabras Dichas'].sum()}\") \n",
    "print(f\"Cantidad de palabras dichas por mujeres: {merged_df_final[merged_df_final['SEX'] == 'F']['Cantidad de Palabras Dichas'].sum()}\") \n",
    "print(f\"Cantidad de palabras dichas por hombres: {merged_df_final[merged_df_final['SEX'] == 'M']['Cantidad de Palabras Dichas'].sum()}\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
