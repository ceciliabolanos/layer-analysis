{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DscBgGDcQOSC"
      },
      "source": [
        "\n",
        "# Cargamos los embeddings de AUDIO y NLP\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/cbolanos/miniconda3/envs/tesis/bin/python\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "print(sys.executable)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioXlCN7CUNqT",
        "outputId": "3a4deb2c-8994-496c-fe2f-3dc2723b49a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "folder_path = '../experiments/layers'\n",
        "\n",
        "file_path = os.path.join(folder_path, f'embeddings_layer6_wav2vec2.json')\n",
        "with open(file_path, 'r') as f:\n",
        "    audio = np.array(json.load(f))\n",
        "\n",
        "file_path = os.path.join(folder_path, f'embeddings_layer3_bert-base-uncased.json')\n",
        "with open(file_path, 'r') as f:\n",
        "    nlp = np.array(json.load(f))\n",
        "\n",
        "with open('words_in_order.json', 'r') as f:\n",
        "    keys = json.load(f)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1l8v7GSQ55oJ"
      },
      "outputs": [],
      "source": [
        "audio = torch.from_numpy(audio)\n",
        "nlp = torch.from_numpy(nlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dDfHoVhwLRva"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.functional.pairwise import pairwise_cosine_similarity\n",
        "import gc\n",
        "\n",
        "k = 46000\n",
        "p = 1\n",
        "large_matrix = torch.zeros(46906, 46906, dtype=torch.float32, device='cpu')\n",
        "batch_size = 5000\n",
        "for i in range(0, nlp.shape[0], batch_size):\n",
        "    end = min(i + batch_size, nlp.shape[0])\n",
        "    batch_embeddings = nlp[i:end]\n",
        "    output = pairwise_cosine_similarity(batch_embeddings, nlp)\n",
        "    values, indices = torch.topk(output, k=k, dim=1)\n",
        "    zero_matrix = torch.zeros_like(output)\n",
        "\n",
        "# Use the indices to place the top k values in the zero matrix\n",
        "    for row_idx, col_indices in enumerate(indices):\n",
        "        zero_matrix[row_idx, col_indices] = values[row_idx] ** p\n",
        "\n",
        "    large_matrix[i:end,:] = zero_matrix\n",
        "\n",
        "    del output, zero_matrix\n",
        "    gc.collect()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paF3HSV5zoyh",
        "outputId": "ce5984a7-df34-4815-b32e-af114f0fcd7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "values, indices = torch.topk(large_matrix[292], k=20)\n",
        "[keys[index.item()] for index in indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "WpfLuKD31ZLs",
        "outputId": "23e0375d-cb68-41b2-dca2-015b3d17a6ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'by'"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "keys[292]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPDxWbb_Hq2_",
        "outputId": "1982f95c-e4af-49d9-e888-3a08f2de5454"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([46906, 768])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nlp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39htRWLPPxmm",
        "outputId": "3bebe9c0-3c8a-440b-c1d0-d53693b568e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([46906, 46906])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "large_matrix.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqateelmRSQ3"
      },
      "source": [
        "# Cargamos audio para testear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_EW1Yzumk3Oe"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torchaudio\n",
        "\n",
        "def get_embeddings_speech(audio_path, model, device):\n",
        "    \"\"\"\n",
        "     Get all the hidden_states for a specific audio\n",
        "    \"\"\"\n",
        "    waveform, sample_rate = torchaudio.load(audio_path)\n",
        "    waveform = waveform.to(device)\n",
        "    with torch.no_grad():\n",
        "        reps = model(waveform)[\"hidden_states\"]\n",
        "\n",
        "    return reps\n",
        "\n",
        "def parse_textgrid(textgrid_path):\n",
        "    \"\"\"\n",
        "    Parses a TextGrid file and returns alignments for words and phones.\n",
        "    \"\"\"\n",
        "    alignments = {'words': [], 'phones': []}\n",
        "    current_section = None\n",
        "\n",
        "    with open(textgrid_path, 'r') as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if 'name = \"words\"' in line:\n",
        "                current_section = 'words'\n",
        "            elif 'name = \"phones\"' in line:\n",
        "                current_section = 'phones'\n",
        "            elif line.startswith('intervals ['):\n",
        "                if current_section:\n",
        "                    xmin, xmax, text = None, None, None\n",
        "            elif line.startswith('xmin ='):\n",
        "                xmin = float(line.split('=')[1].strip())\n",
        "            elif line.startswith('xmax ='):\n",
        "                xmax = float(line.split('=')[1].strip())\n",
        "            elif line.startswith('text ='):\n",
        "                text = line.split('=')[1].strip().strip('\"')\n",
        "                if text:  # Ignore empty intervals\n",
        "                    alignments[current_section].append((xmin, xmax, text))\n",
        "\n",
        "    return alignments\n",
        "\n",
        "def remove_first_directory(path):\n",
        "    parts = path.split(os.path.sep)\n",
        "    if len(parts) > 1:\n",
        "        return os.path.join(*parts[3:])\n",
        "    return path\n",
        "\n",
        "\n",
        "def read_line_by_identifier(directory_path, identifier):\n",
        "    # Find the .txt file in the given directory\n",
        "    for file_name in os.listdir(directory_path):\n",
        "        if file_name.endswith('.txt'):\n",
        "            file_path = os.path.join(directory_path, file_name)\n",
        "            break\n",
        "    else:\n",
        "        return \"Text file not found in the directory.\"\n",
        "\n",
        "    # Read the specified line from the found text file\n",
        "    with open(file_path, 'r') as file:\n",
        "        for line in file:\n",
        "            if line.startswith(identifier):\n",
        "                return line.strip().replace(identifier, '').strip()\n",
        "\n",
        "\n",
        "def match_words_to_frames(alignments, frame_length, stride):\n",
        "    \"\"\"\n",
        "    Matches frame indices to word from alignments, correctly calculating\n",
        "    start and end frames based on the provided alignments.\n",
        "    \"\"\"\n",
        "    # Convert frame_length and stride from milliseconds to seconds for consistency\n",
        "    frame_length_sec = frame_length / 1000.0\n",
        "    stride_sec = stride / 1000.0\n",
        "    words = {}\n",
        "    for key in alignments:\n",
        "        for xmin, xmax, text in alignments[key]:\n",
        "            # Calculate the frame index for the start and end of the interval\n",
        "            # Start frame is calculated by dividing xmin by stride_sec, because each new frame starts every stride_sec seconds\n",
        "            start_frame = int(xmin / stride_sec)\n",
        "            end_frame = int(xmax / stride_sec) if xmax > 0 else 0\n",
        "            if key == 'words':\n",
        "                if text not in words:\n",
        "                   words[text] = []\n",
        "                words[text].append((start_frame, end_frame))\n",
        "    return words\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3xRh2AKkrhq",
        "outputId": "7ffe05bf-146e-47f0-e223-e707201dae30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'every': [(23, 39)],\n",
              " 'chance': [(39, 58)],\n",
              " 'she': [(58, 66)],\n",
              " 'could': [(66, 76)],\n",
              " 'steal': [(76, 93)],\n",
              " 'after': [(93, 107), (185, 200)],\n",
              " 'practice': [(107, 129)],\n",
              " 'hours': [(129, 143)],\n",
              " 'were': [(143, 150), (334, 341)],\n",
              " 'over': [(150, 175)],\n",
              " 'and': [(175, 185)],\n",
              " 'the': [(200, 204), (265, 269), (478, 484), (505, 509), (541, 546)],\n",
              " 'clamorous': [(204, 235)],\n",
              " 'demands': [(235, 260)],\n",
              " 'of': [(260, 265), (499, 505)],\n",
              " 'boys': [(269, 291)],\n",
              " 'upon': [(291, 306)],\n",
              " 'her': [(306, 312)],\n",
              " 'time': [(312, 332)],\n",
              " 'fully': [(341, 357)],\n",
              " 'satisfied': [(357, 394)],\n",
              " 'was': [(413, 428)],\n",
              " 'seized': [(428, 449)],\n",
              " 'to': [(449, 457), (535, 541)],\n",
              " 'fly': [(457, 474)],\n",
              " 'on': [(474, 478)],\n",
              " 'wings': [(484, 499)],\n",
              " 'wind': [(509, 531)],\n",
              " 'flowers': [(546, 579)]}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "alignments = parse_textgrid('../datasets/alignments/test-clean/237/126133/237-126133-0001.TextGrid')\n",
        "words = match_words_to_frames(alignments, 25, 20)\n",
        "words\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "vWH9dHLyRRNE"
      },
      "outputs": [],
      "source": [
        "# Obetenemos la representacion a trav√©s del ENCODER WAV2VEC2\n",
        "import s3prl.hub as hub\n",
        "\n",
        "model = getattr(hub, 'wav2vec2')()\n",
        "model = model.to('cpu')\n",
        "audio_path = '../datasets/librispeech-raw/test-clean/237/126133/237-126133-0001.flac'\n",
        "reps = get_embeddings_speech(audio_path, model, 'cpu')\n",
        "averaged_rep = reps[7][0][23:39+1].mean(dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Ub-u-l3PTrE4"
      },
      "outputs": [],
      "source": [
        "averaged_rep_2d = averaged_rep.unsqueeze(0).double()\n",
        "relative_rep = pairwise_cosine_similarity(averaged_rep_2d, audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_gRJBxi35II",
        "outputId": "d2c8fb06-edcc-472f-f330-506482e47760"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'everything',\n",
              " 'every',\n",
              " 'every',\n",
              " 'everything',\n",
              " 'every',\n",
              " 'everyday',\n",
              " 'whichever',\n",
              " 'everywhere',\n",
              " 'every',\n",
              " 'every']"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "values, indices = torch.topk(relative_rep[0], k=20)\n",
        "[keys[index.item()] for index in indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Qn4tHkJyUw9i"
      },
      "outputs": [],
      "source": [
        "batch_size = 1000  # Adjust this based on your GPU memory capacity\n",
        "\n",
        "# Store results\n",
        "similarity_results = []\n",
        "\n",
        "for i in range(0, large_matrix.size(0), batch_size):\n",
        "    end = min(i + batch_size, large_matrix.size(0))\n",
        "    batch = large_matrix[i:end, :] # Move batch to GPU if not already\n",
        "    similarity = pairwise_cosine_similarity(relative_rep.float(), batch)\n",
        "    similarity_results.extend(similarity.cpu())  # Move results to CPU to save GPU memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "wBnk9OWeVmPZ"
      },
      "outputs": [],
      "source": [
        "full_similarity = torch.cat(similarity_results, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "-gh-IyDiWems"
      },
      "outputs": [],
      "source": [
        "# Obtenemos los k mas similares\n",
        "values, indices = torch.topk(full_similarity, k=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPpeVw6eWszp",
        "outputId": "8430f178-c22b-43ba-a3b7-ac9d790d7394"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['surely',\n",
              " 'occasionally',\n",
              " 'occasionally',\n",
              " 'curiously',\n",
              " 'accustomed',\n",
              " 'next',\n",
              " 'scarcely',\n",
              " 'anyway',\n",
              " 'fortunately',\n",
              " 'whence',\n",
              " 'fortunately',\n",
              " 'wise',\n",
              " 'yes',\n",
              " 'every',\n",
              " 'often',\n",
              " 'occasionally',\n",
              " 'perhaps',\n",
              " 'sufficient',\n",
              " 'fortunately',\n",
              " 'probably']"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[keys[index.item()] for index in indices]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
