{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DscBgGDcQOSC"
      },
      "source": [
        "\n",
        "# Notebook para probar ASIF - Retrieval\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Cargamos los embeddings de AUDIO y NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ioXlCN7CUNqT",
        "outputId": "3a4deb2c-8994-496c-fe2f-3dc2723b49a4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchaudio\n",
        "\n",
        "folder_path = '../experiments/layers'\n",
        "\n",
        "file_path = os.path.join(folder_path, f'embeddings_layer6_wav2vec2.json')\n",
        "with open(file_path, 'r') as f:\n",
        "    audio = np.array(json.load(f))\n",
        "\n",
        "file_path = os.path.join(folder_path, f'embeddings_layer3_bert-base-uncased.json')\n",
        "with open(file_path, 'r') as f:\n",
        "    nlp = np.array(json.load(f))\n",
        "\n",
        "with open('words_in_order.json', 'r') as f:\n",
        "    keys = json.load(f)\n",
        "\n",
        "\n",
        "audio = torch.from_numpy(audio)\n",
        "nlp = torch.from_numpy(nlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos la matriz de similitud entre los embeddings de nlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "dDfHoVhwLRva"
      },
      "outputs": [],
      "source": [
        "from torchmetrics.functional.pairwise import pairwise_cosine_similarity\n",
        "import gc\n",
        "\n",
        "k = 46000\n",
        "p = 1\n",
        "n = nlp.shape[0]\n",
        "\n",
        "large_matrix = torch.zeros(n, n, dtype=torch.float32, device='cpu')\n",
        "batch_size = 5000\n",
        "\n",
        "for i in range(0, n, batch_size):\n",
        "    end = min(i + batch_size, nlp.shape[0])\n",
        "    batch_embeddings = nlp[i:end]\n",
        "    output = pairwise_cosine_similarity(batch_embeddings, nlp)\n",
        "    values, indices = torch.topk(output, k=k, dim=1)\n",
        "    zero_matrix = torch.zeros_like(output)\n",
        "\n",
        "    # Use the indices to place the top k values in the zero matrix\n",
        "    for row_idx, col_indices in enumerate(indices):\n",
        "        zero_matrix[row_idx, col_indices] = values[row_idx] ** p\n",
        "\n",
        "    large_matrix[i:end,:] = zero_matrix\n",
        "\n",
        "    del output, zero_matrix\n",
        "    gc.collect()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Queremos confirmar que los embeddings dentro de un mismo espacio están bien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paF3HSV5zoyh",
        "outputId": "ce5984a7-df34-4815-b32e-af114f0fcd7e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by',\n",
              " 'by']"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f'Para la siguiente palabra: {keys[292]}, se obtienen las siguientes palabras como retrievals:')\n",
        "values, indices = torch.topk(large_matrix[292], k=20)\n",
        "[keys[index.item()] for index in indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqateelmRSQ3"
      },
      "source": [
        "# Cargamos audio para testear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3xRh2AKkrhq",
        "outputId": "7ffe05bf-146e-47f0-e223-e707201dae30"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'every': [(23, 39)],\n",
              " 'chance': [(39, 58)],\n",
              " 'she': [(58, 66)],\n",
              " 'could': [(66, 76)],\n",
              " 'steal': [(76, 93)],\n",
              " 'after': [(93, 107), (185, 200)],\n",
              " 'practice': [(107, 129)],\n",
              " 'hours': [(129, 143)],\n",
              " 'were': [(143, 150), (334, 341)],\n",
              " 'over': [(150, 175)],\n",
              " 'and': [(175, 185)],\n",
              " 'the': [(200, 204), (265, 269), (478, 484), (505, 509), (541, 546)],\n",
              " 'clamorous': [(204, 235)],\n",
              " 'demands': [(235, 260)],\n",
              " 'of': [(260, 265), (499, 505)],\n",
              " 'boys': [(269, 291)],\n",
              " 'upon': [(291, 306)],\n",
              " 'her': [(306, 312)],\n",
              " 'time': [(312, 332)],\n",
              " 'fully': [(341, 357)],\n",
              " 'satisfied': [(357, 394)],\n",
              " 'was': [(413, 428)],\n",
              " 'seized': [(428, 449)],\n",
              " 'to': [(449, 457), (535, 541)],\n",
              " 'fly': [(457, 474)],\n",
              " 'on': [(474, 478)],\n",
              " 'wings': [(484, 499)],\n",
              " 'wind': [(509, 531)],\n",
              " 'flowers': [(546, 579)]}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from alignments.utils_alignments import parse_textgrid, match_words_to_frames\n",
        "alignments = parse_textgrid('../datasets/alignments/test-clean/237/126133/237-126133-0001.TextGrid')\n",
        "words = match_words_to_frames(alignments, 25, 20, line_content='')\n",
        "words\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Seleccionamos alguna de las palabras que querramos probar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "vWH9dHLyRRNE"
      },
      "outputs": [],
      "source": [
        "# Obetenemos la representacion a través del ENCODER WAV2VEC2\n",
        "import s3prl.hub as hub\n",
        "from embeddings.utils_embeddings import get_embeddings_speech\n",
        "\n",
        "model = getattr(hub, 'wav2vec2')()\n",
        "model = model.to('cpu')\n",
        "audio_path = '../datasets/librispeech-raw/test-clean/237/126133/237-126133-0001.flac'\n",
        "reps = get_embeddings_speech(audio_path, model, 'cpu')\n",
        "averaged_rep = reps[7][0][23:39+1].mean(dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Obtenemos la representación relativa de ese embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "Ub-u-l3PTrE4"
      },
      "outputs": [],
      "source": [
        "averaged_rep_2d = averaged_rep.unsqueeze(0).double()\n",
        "relative_rep = pairwise_cosine_similarity(averaged_rep_2d, audio)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confirmamos que usando esa representación relativa podamos devolver los embeddings de audio similares. Para confirmar que estamos haciendo las cosas bien."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_gRJBxi35II",
        "outputId": "d2c8fb06-edcc-472f-f330-506482e47760"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'every',\n",
              " 'everything',\n",
              " 'every',\n",
              " 'every',\n",
              " 'everything',\n",
              " 'every',\n",
              " 'everyday',\n",
              " 'whichever',\n",
              " 'everywhere',\n",
              " 'every',\n",
              " 'every']"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "values, indices = torch.topk(relative_rep[0], k=20)\n",
        "[keys[index.item()] for index in indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculamos los embeddings de nlp más similares a la representación relativa del embedding de audio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "Qn4tHkJyUw9i"
      },
      "outputs": [],
      "source": [
        "batch_size = 1000 \n",
        "similarity_results = []\n",
        "\n",
        "for i in range(0, large_matrix.size(0), batch_size):\n",
        "    end = min(i + batch_size, large_matrix.size(0))\n",
        "    batch = large_matrix[i:end, :] \n",
        "    similarity = pairwise_cosine_similarity(relative_rep.float(), batch)\n",
        "    similarity_results.extend(similarity.cpu())\n",
        "full_similarity = torch.cat(similarity_results, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "-gh-IyDiWems"
      },
      "outputs": [],
      "source": [
        "# Obtenemos los k mas similares\n",
        "values, indices = torch.topk(full_similarity, k=20)\n",
        "[keys[index.item()] for index in indices]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
